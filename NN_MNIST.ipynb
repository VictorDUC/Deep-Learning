{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification using neural networks\n",
    "\n",
    "We study here the performance of feedforward neural networks to classify digits in the MNIST set. \n",
    "\n",
    "**There are 2 questions to answer.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "# set up the random number generator: given seed for reproducibility, None otherwise\n",
    "# (see https://numpy.org/doc/stable/reference/random/generator.html#numpy.random.default_rng)\n",
    "my_seed = 1\n",
    "rng = np.random.default_rng(seed=my_seed) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Construction of the dataset \n",
    "\n",
    "We use the MNIST dataset already encountered in various hands-on sessions. We download it through PyTorch here (note: I had to run \"jupyter nbextension enable --py widgetsnbextension\" in the command line for this to work; maybe also \"pip3 install --upgrade ipywidgets\")."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "full_train_dataset = torchvision.datasets.MNIST(root='./data',train=True,transform=transforms.ToTensor(),download=True)\n",
    "test_dataset = torchvision.datasets.MNIST(root='./data',train=False,transform=transforms.ToTensor(),download=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We first explore the format of the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset MNIST\n",
      "    Number of datapoints: 60000\n",
      "    Root location: ./data\n",
      "    Split: Train\n",
      "    StandardTransform\n",
      "Transform: ToTensor()\n",
      "\n",
      "format of train data: torch.uint8\n",
      "Dataset MNIST\n",
      "    Number of datapoints: 10000\n",
      "    Root location: ./data\n",
      "    Split: Test\n",
      "    StandardTransform\n",
      "Transform: ToTensor()\n",
      "\n",
      "format of test data: torch.uint8\n"
     ]
    }
   ],
   "source": [
    "print(full_train_dataset)\n",
    "print(\"\\nformat of train data:\",full_train_dataset.data.dtype)\n",
    "print(test_dataset)\n",
    "print(\"\\nformat of test data:\",test_dataset.data.dtype)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We next construct a training set and a validation set out of the full training set. In order to make the training faster, we can reduce the size of the dataset if we want."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "reduced_length = 50000\n",
    "validation_length = 10000\n",
    "# check whether we go out of bounds in terms of use of training data points\n",
    "assert(reduced_length+validation_length<=full_train_dataset.data.shape[0])\n",
    "# we can then extract the corresponding indices\n",
    "indices_train = range(reduced_length)\n",
    "indices_validation = range(reduced_length,reduced_length+validation_length)\n",
    "train_dataset = torch.utils.data.Subset(full_train_dataset, indices=indices_train)\n",
    "validation_dataset = torch.utils.data.Subset(full_train_dataset, indices=indices_validation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can plot the first elements of the resulting data set in order to see what they looks like."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x288 with 10 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(10, 4))\n",
    "\n",
    "picture_loader = torch.utils.data.DataLoader(dataset=validation_dataset,batch_size=25,shuffle=True)\n",
    "examples = iter(picture_loader)\n",
    "example_data, example_labels = examples.next()\n",
    "\n",
    "for i in range(10):\n",
    "    plt.subplot(2, 5, i+1)\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "    plt.grid(False)\n",
    "    # color map = binary, other choices here https://matplotlib.org/stable/tutorials/colors/colormaps.html\n",
    "    plt.imshow(example_data[i][0].reshape(28,28), cmap=plt.cm.binary)     \n",
    "    plt.title(example_labels[i].item())\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introducing neural networks\n",
    "\n",
    "We first introduce the class of neural networks we consider. Activation functions and topology can be modified."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralNet(nn.Module):\n",
    "    \n",
    "    def __init__(self, input_size, hidden_size, num_classes):\n",
    "         super(NeuralNet, self).__init__()\n",
    "         self.input_size = input_size\n",
    "         self.relu = nn.ReLU()\n",
    "         self.layer_1 = nn.Linear(input_size, hidden_size)\n",
    "         self.layer_2 = nn.Linear(hidden_size, num_classes)\n",
    "        \n",
    "    def forward(self, x):\n",
    "         out = self.layer_1(x)\n",
    "         out = self.relu(out)\n",
    "         out = self.layer_2(out)\n",
    "         # no activation and no softmax at the end since the loss function requires only unnormalized logits\n",
    "         return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We next specify the parameters and loss function. See https://pytorch.org/docs/stable/generated/torch.nn.CrossEntropyLoss.html for the cross entropy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#--- construction of the model: from input_size to num_classes with one hidden layer --- \n",
    "input_size = 784\n",
    "hidden_size = 50\n",
    "num_classes = 10\n",
    "model = NeuralNet(input_size, hidden_size, num_classes)\n",
    "\n",
    "#--- Loss and optimizer ---\n",
    "num_epochs = 30\n",
    "batch_size = 60\n",
    "learning_rate = 0.01 \n",
    "loss_function = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "#--- data --- \n",
    "train_loader = torch.utils.data.DataLoader(dataset=train_dataset,batch_size=batch_size,shuffle=True)\n",
    "validation_loader = torch.utils.data.DataLoader(dataset=validation_dataset,batch_size=validation_length,shuffle=True)\n",
    "test_loader = torch.utils.data.DataLoader(dataset=test_dataset,batch_size=test_dataset.data.shape[0],shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can check that the test and validation sets consist of a single batch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation: torch.Size([10000, 1, 28, 28])\n",
      "test: torch.Size([10000, 1, 28, 28])\n"
     ]
    }
   ],
   "source": [
    "for i, (images, labels) in enumerate(validation_loader):\n",
    "    print('validation:',images.shape)\n",
    "for i, (images, labels) in enumerate(test_loader):\n",
    "    print('test:',images.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 1.** Perform the training. What accuracy can you get?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- Better model // saving\n",
      "Epoch [1/30], Train loss: 0.0786, Validation loss: 0.1453\n",
      "-- Better model // saving\n",
      "Epoch [2/30], Train loss: 0.0136, Validation loss: 0.1395\n",
      "Epoch [3/30], Train loss: 0.0046, Validation loss: 0.1527\n",
      "Epoch [4/30], Train loss: 0.1342, Validation loss: 0.1456\n",
      "Epoch [5/30], Train loss: 0.0209, Validation loss: 0.1434\n",
      "-- Better model // saving\n",
      "Epoch [6/30], Train loss: 0.1318, Validation loss: 0.1317\n",
      "Epoch [7/30], Train loss: 0.0016, Validation loss: 0.1484\n",
      "Epoch [8/30], Train loss: 0.0210, Validation loss: 0.1840\n",
      "Epoch [9/30], Train loss: 0.0009, Validation loss: 0.1696\n",
      "Epoch [10/30], Train loss: 0.0197, Validation loss: 0.1971\n",
      "Epoch [11/30], Train loss: 0.0014, Validation loss: 0.1851\n",
      "Epoch [12/30], Train loss: 0.1079, Validation loss: 0.1888\n",
      "Epoch [13/30], Train loss: 0.0466, Validation loss: 0.2084\n",
      "Epoch [14/30], Train loss: 0.0737, Validation loss: 0.2222\n",
      "Epoch [15/30], Train loss: 0.1144, Validation loss: 0.2489\n",
      "Epoch [16/30], Train loss: 0.0000, Validation loss: 0.2109\n",
      "The test loss no longer decreases... STOP\n"
     ]
    }
   ],
   "source": [
    "early_stopping_steps = 10\n",
    "min_validation_loss = 10000\n",
    "nb_steps_where_test_loss_did_not_decrease = 0\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    for i, (images, labels) in enumerate(train_loader):\n",
    "         # original shape [batch_size, 1, 28, 28], resized to [batch_size, 784]\n",
    "         images = images.reshape(-1, 28*28)\n",
    "         # Forward pass\n",
    "         outputs = model(images)\n",
    "         loss = loss_function(outputs, labels)\n",
    "         # Backward and optimize\n",
    "         optimizer.zero_grad()\n",
    "         loss.backward()\n",
    "         optimizer.step()\n",
    "    # validation loss for early stopping\n",
    "    nb_steps_where_test_loss_did_not_decrease += 1\n",
    "    if (nb_steps_where_test_loss_did_not_decrease > early_stopping_steps):\n",
    "        print('The test loss no longer decreases... STOP')\n",
    "        break\n",
    "    for j, (validation_images, validation_labels) in enumerate(validation_loader):\n",
    "         validation_loss = loss_function(model(validation_images.reshape(-1, 28*28)),validation_labels)\n",
    "    if (validation_loss < min_validation_loss):\n",
    "        min_validation_loss = validation_loss\n",
    "        nb_steps_where_test_loss_did_not_decrease = 0\n",
    "        print(f'-- Better model // saving')\n",
    "        torch.save(model, 'best_model')    \n",
    "    print(f'Epoch [{epoch+1}/{num_epochs}], Train loss: {loss.item():.4f}, Validation loss: {validation_loss.item():.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can then test the quality of the predictions made by the network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the network on the 10000 test images: 96.73 %\n"
     ]
    }
   ],
   "source": [
    "del model\n",
    "model = torch.load('best_model')\n",
    "\n",
    "# no gradient needed for evaluation\n",
    "with torch.no_grad():\n",
    "    n_correct = 0\n",
    "    n_samples = 0\n",
    "    for images, labels in test_loader:\n",
    "        images = images.reshape(-1, 28*28)\n",
    "        outputs = model(images)\n",
    "        # max returns (value ,index)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        n_samples += labels.size(0)\n",
    "        n_correct += (predicted == labels).sum().item()\n",
    "        \n",
    "acc = 100.0 * n_correct / n_samples\n",
    "print(f'Accuracy of the network on the 10000 test images: {acc} %')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 2.** Try to improve the performance by various means (adding an extra hidden layer, regularizing with dropout, changing the optimization algorithm, etc). What is the best test accuracy you can achieve?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# note: this could be made simpler with Sequential() to append layers in an automated manner\n",
    "# see for instance the presentation in Section 6.1.2 of \n",
    "# http://preview.d2l.ai/d2l-en/master/chapter_builders-guide/model-construction.html\n",
    "class NeuralNet(nn.Module):\n",
    "    \n",
    "    def __init__(self, input_size, hidden_size_1, hidden_size_2, num_classes, dropout_proba, dropout_input):\n",
    "         super(NeuralNet, self).__init__()\n",
    "         self.input_size = input_size\n",
    "         self.relu = nn.ReLU()\n",
    "         self.dropout = nn.Dropout(dropout_proba)\n",
    "         self.dropout_input = nn.Dropout(dropout_input)\n",
    "         self.layer_1 = nn.Linear(input_size, hidden_size_1)\n",
    "         self.layer_2 = nn.Linear(hidden_size_1, hidden_size_2) \n",
    "         self.layer_3 = nn.Linear(hidden_size_2, num_classes)\n",
    "        \n",
    "    def forward(self, x):\n",
    "         out = self.dropout_input(x)\n",
    "         out = self.layer_1(out)\n",
    "         out = self.relu(out)\n",
    "         out = self.dropout(out)\n",
    "         out = self.layer_2(out)\n",
    "         out = self.relu(out)\n",
    "         out = self.dropout(out)\n",
    "         out = self.layer_3(out)\n",
    "         # still no activation at the end\n",
    "         return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- Better model // saving\n",
      "Epoch [1/30], Train loss: 0.2017, Validation loss: 0.1787\n",
      "-- Better model // saving\n",
      "Epoch [2/30], Train loss: 0.1861, Validation loss: 0.1624\n",
      "-- Better model // saving\n",
      "Epoch [3/30], Train loss: 0.2336, Validation loss: 0.1421\n",
      "Epoch [4/30], Train loss: 0.2626, Validation loss: 0.1526\n",
      "-- Better model // saving\n",
      "Epoch [5/30], Train loss: 0.2920, Validation loss: 0.1262\n",
      "Epoch [6/30], Train loss: 0.1688, Validation loss: 0.1393\n",
      "Epoch [7/30], Train loss: 0.0833, Validation loss: 0.1380\n",
      "Epoch [8/30], Train loss: 0.1879, Validation loss: 0.1291\n",
      "Epoch [9/30], Train loss: 0.3195, Validation loss: 0.1497\n",
      "Epoch [10/30], Train loss: 0.2236, Validation loss: 0.1319\n",
      "The test loss no longer decreases... STOP\n"
     ]
    }
   ],
   "source": [
    "#--- construction of the model: from input_size to num_classes with one hidden layer --- \n",
    "input_size = 784\n",
    "hidden_size_1 = 50\n",
    "hidden_size_2 = 20\n",
    "num_classes = 10\n",
    "dropout_proba = 0.1 # dropout rate on hidden nodes\n",
    "dropout_input = 0. # dropout rate on input values\n",
    "model = NeuralNet(input_size, hidden_size_1, hidden_size_2, num_classes, dropout_proba, dropout_input)\n",
    "\n",
    "#--- Loss and optimizer ---\n",
    "num_epochs = 30\n",
    "batch_size = 100\n",
    "learning_rate = 0.01\n",
    "loss_function = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate) # could be SGD instead of Adam here\n",
    "early_stopping_steps = 5\n",
    "min_validation_loss = 10000\n",
    "nb_steps_where_test_loss_did_not_decrease = 0\n",
    "\n",
    "#--- data --- \n",
    "train_loader = torch.utils.data.DataLoader(dataset=train_dataset,batch_size=batch_size,shuffle=True)\n",
    "validation_loader = torch.utils.data.DataLoader(dataset=validation_dataset,batch_size=validation_length,shuffle=True)\n",
    "test_loader = torch.utils.data.DataLoader(dataset=test_dataset,batch_size=test_dataset.data.shape[0],shuffle=True)\n",
    "\n",
    "#------ actual training -----------\n",
    "for epoch in range(num_epochs):\n",
    "    model.train() # to go to train mode and perform dropout\n",
    "    for i, (images, labels) in enumerate(train_loader):\n",
    "         images = images.reshape(-1, 28*28)\n",
    "         # Forward pass\n",
    "         outputs = model(images)\n",
    "         loss = loss_function(outputs, labels)\n",
    "         # Backward and optimize\n",
    "         optimizer.zero_grad()\n",
    "         loss.backward()\n",
    "         optimizer.step()\n",
    "    # validation loss for early stopping\n",
    "    model.eval() # to go to evaluation mode and not perform dropout\n",
    "    nb_steps_where_test_loss_did_not_decrease += 1\n",
    "    if (nb_steps_where_test_loss_did_not_decrease > early_stopping_steps):\n",
    "        print('The test loss no longer decreases... STOP')\n",
    "        break\n",
    "    for j, (validation_images, validation_labels) in enumerate(validation_loader):\n",
    "         validation_loss = loss_function(model(validation_images.reshape(-1, 28*28)),validation_labels)\n",
    "    if (validation_loss < min_validation_loss):\n",
    "        min_validation_loss = validation_loss\n",
    "        nb_steps_where_test_loss_did_not_decrease = 0\n",
    "        print(f'-- Better model // saving')\n",
    "        torch.save(model, 'best_model')    \n",
    "    print(f'Epoch [{epoch+1}/{num_epochs}], Train loss: {loss.item():.4f}, Validation loss: {validation_loss.item():.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the network on the 10000 test images: 96.27 %\n"
     ]
    }
   ],
   "source": [
    "del model\n",
    "model = torch.load('best_model')\n",
    "model.eval() \n",
    "\n",
    "with torch.no_grad():\n",
    "    n_correct = 0\n",
    "    n_samples = 0\n",
    "    for images, labels in test_loader:\n",
    "        images = images.reshape(-1, 28*28)\n",
    "        outputs = model(images)\n",
    "        # max returns (value ,index)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        n_samples += labels.size(0)\n",
    "        n_correct += (predicted == labels).sum().item()\n",
    "        \n",
    "acc = 100.0 * n_correct / n_samples\n",
    "print(f'Accuracy of the network on the 10000 test images: {acc} %')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
